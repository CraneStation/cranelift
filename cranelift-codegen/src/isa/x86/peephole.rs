use crate::cursor::{Cursor, EncCursor};
use crate::ir::types::{I32, I64};
use crate::ir::{Function, Inst, InstBuilder, InstructionData, Opcode, ValueDef};
use crate::isa::TargetIsa;

/// Remove spurious unsigned-extended moves from I32 to I64 when the previous instruction likely
/// already cleared up the upper 32 bits.
///
/// There is an invariant in the Intel x86 architecture on 64 bits that if an instruction writes
/// into a 32-bit register, then the upper 32 bits will be zero-extended. Whenever this happens, it
/// means that a (movl $reg, $reg), as generated by an uextend.i64.i32, will only have one
/// side-effect: clearing up the high 32 bits. In this case, this uextend can be removed.
///
/// Since this is a bit risky to perform this optimization for any instruction/encoding, a list of
/// known instruction/encodings has been recorded here, and it should take care of most of the
/// cases.
fn optimize_uextend(pos: &mut EncCursor, inst: Inst, isa: &dyn TargetIsa) {
    use log::warn;
    if let InstructionData::Unary {
        opcode: Opcode::Uextend,
        arg,
    } = pos.func.dfg[inst]
    {
        let to_ty = pos.func.dfg.ctrl_typevar(inst);
        if to_ty != I64 {
            return;
        }

        if let ValueDef::Result(def_inst, _) = pos.func.dfg.value_def(arg) {
            if pos.func.dfg.ctrl_typevar(def_inst) != I32 {
                return;
            }
            debug_assert_eq!(pos.func.dfg.value_type(arg), I32);

            // If the input and output locations differ, it can't be a no-op.
            let result = pos.func.dfg.inst_results(inst)[0];
            if pos.func.locations[result] != pos.func.locations[arg] {
                return;
            }

            // TODO actually limit this optimization to a set of known instruction / encodings.
            let encoding = &pos.func.encodings[def_inst];
            warn!("producer: {} {}", def_inst, encoding);

            pos.func.dfg.replace(inst).uextend_nop(to_ty, arg);
            debug_assert!(pos.func.update_encoding(inst, isa).is_ok());
        }
    }
}

pub fn run(isa: &TargetIsa, func: &mut Function) {
    // At the moment, only the uextend optimization is implemented, which makes sense only on x86
    // 64 bits.
    if isa.pointer_bits() != 64 {
        return;
    }

    let mut pos = EncCursor::new(func, isa);
    while let Some(_ebb) = pos.next_ebb() {
        while let Some(inst) = pos.next_inst() {
            optimize_uextend(&mut pos, inst, isa);
        }
    }
}
